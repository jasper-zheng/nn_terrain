[{
                "url": "/nn_terrain/tags/open-graph-image",
                "title": "Tag",
                "content": " open-graph-image "
            },
                {
                    "url": "/nn_terrain/installation/",
                    "title": "Download and Installation",
                    "content": "Installing the nn.terrain~ externals to MaxMSP/Max4Live.  This repository is a set of MaxMSP/Max4Live externals to build, visualise, and program latent terrain:ObjectDescriptionnn.terrain~ Load, build, train, and save a terrain.Perform the coordinates-to-latents mapping. nn.terrain.encodeUsing a pre-trained autoencoder to encode audio buffers into latent trajectories, as training data for nn.terrain~.nn.terrain.recordManually recording latent trajectories, as training data for nn.terrain~.nn.terrain.guiEdit spatial trajectories, as training data for nn.terrain~.Visualise the terrain.Create and program trajectory playbacks.All externals above are designed to work together with nn~, which is a MaxMSP/Max4Live external developed by acids-ircam to load and use deep learning realtime audio processing models:ObjectDescriptionnn~ Hosting the decoder of an AI audio autoencoder, to decode latents to audio in realtime. DownloadDepending on which version of nn~ you&#39;re using:If you&#39;re using nn~ v1.5.6 (torch v2.0.0/2.0.1) (the 2023 version): Please download nn.terrain~ v1.5.6.If you&#39;re using nn~ v1.6.0 (torch v2.5.0/2.5.1) (the 2025 version): Please download nn.terrain~ v1.6.0.While the 1.6.0 nn~ offers amazing add-on functionalities, I personally use the 1.5.6 version more often because it does exactly what I need already, and it&#39;s more stable with nn.terrain~.If you&#39;re unsure which version you&#39;re using, this can be checked from your Max console when an nn~ instance is first opened in Max:If you have a customised nn~ like me, you might need to consider compiling your own nn.terrain~ from source, please see instructions Compile from Source.Installationnn.terrain~ needs to be installed in different ways, depending on which version of nn~ you&#39;re using:With nn~ v1.5.6macOSUncompress the .tar.gz file into the Package folder of your Max documents, which is usually in ~/Documents/Max 9/Packages.Reopen Max and you can find all nn.terrain objects.You might get a quarantine warning, proceed will disable this warning.WindowsUncompress the .tar.gz file into the Package folder of your Max documents, which is usually in ~/Documents/Max 9/Packages/Copy all .dll files in the package next to the Max.exe executable (if you have already done this for nn~, you don&#39;t need to do this again).With nn~ v1.6.0macOSUncompress the .tar.gz fileIn ~/Documents/Max 9/Packages, copy and merge the unzipped folders to the nn_tilde folder, make sure that all externals (e.g., nn.terrain~.mxo) are placed next to nn~.mxo in the same folder.Reopen Max and you can find all nn.terrain objects.You might get a quarantine warning, proceed will disable this warning.WindowsTo be updated soon.If the externals have trouble opening in Max, or doesn&#39;t work correctly with nn~ you might considering compiling the externals yourself, see Compile from Source."
                },
                {
                    "url": "/nn_terrain/instructions/",
                    "title": "Instructions",
                    "content": "Some instructions for getting started exploring AI audio generation with latent terrain.  "
                },
                {
                    "url": "/nn_terrain/pre-trained/",
                    "title": "Pre-Trained Terrains (Presets)",
                    "content": "Some already built terrains to get started with.  Make sure to have both:an autoencoder (a .ts file)a terrain model (a .pt file).Autoencoder: Percussion - RAVE v1Pre-trained autoencoder author: Antoine CaillonDownload from RAVE official repository percussion.ts.Terrain: percussion-terrain-demo.ptConfig: 2 inputs 4 outputs, range: -16, -4, 16, 4Autoencoder: Music2Latent-ScriptedOriginal model is the work by Marco Pasini at SonyCSLParis.Scripted model can be downloaded from music2latent.ts."
                },
                {
                    "url": "/nn_terrain/compile/",
                    "title": "Compile from Source",
                    "content": "Building nn.terrain~ externals from the source code.  If the externals have trouble opening in Max, or doesn&#39;t work correctly with nn_tilde, you might want to build the externals yourself:PrerequisitesMacOS:Xcode 11 or 12 (you can get from the App Store for free).Download LibTorch here and unzip it to a known directory. LibTorch&#39;s torch version should be the same as nn_tilde.Install a recent version of CMake (version 3.19 or higher).Windows:Download LibTorch here and unzip it to a known directory. LibTorch&#39;s torch version should be the same as nn_tilde.If you would like to enable GPU training/inference, you&#39;ll need to select the CUDA version of LibTorch, and have the corresponding CUDA ToolKit.Install a recent version of CMake (version 3.19 or higher).Build on MacOSRecursively clone this repository into Max&#39;s Packages folder. Terminal command:git clone https://github.com/jasper-zheng/nn_terrain.git --recursiveIn Terminal, cd into the nn_terrain folder you cloned, and make a new folder named build. and cd into that folder:cd nn_terrainmkdir buildcd buildRun the command below to generate an Xcode project, replace path/to/libtorch to the libtorch folder you&#39;ve downloaded:cmake ../src/ -G Xcode -DCMAKE_PREFIX_PATH=/path/to/libtorch -DCMAKE_BUILD_TYPE=Release -DCMAKE_OSX_ARCHITECTURES=arm64 An Xcode project will be created in this build folder, you can either open the Xcode project and build it from there, or build by running the command below:cmake --build .The .mxo files will be created in the src/externals folder, move them ~/Documents/Max 9/Packages/nn_terrain/externals/Additionally, taken from min-devkit:If you are running on a Mac with Apple Silicon, you might see an error cannot be loaded due to system security policy when loading your externals in Max. To resolve this, you can ad-hoc codesign your external with codesign --force --deep, this can be added in Xcode &amp;quot;Build Settings&amp;quot; page, in the &amp;quot;Signing&amp;quot; section, in &amp;quot;Other Code Signing Flags&amp;quot;.Build on WindowsRecursively clone this repository into Max&#39;s Packages folder. Terminal command:git clone https://github.com/jasper-zheng/nn_terrain.git --recurse-submodulesIn Terminal, cd into the nn_terrain folder you cloned, and make a new folder named build. and cd into that folder:cd nn_terrainmkdir buildcd buildThen run the command below to generate a project buildsystem, replace pathtolibtorch to the libtorch folder you&#39;ve downloaded, and make sure Visual Studio 17 2022 is set to your build system generator (run cmake --help to get a list of available options).cmake ..src -A x64 -DCMAKE_PREFIX_PATH=&amp;quot;pathtolibtorch&amp;quot; -G &amp;quot;Visual Studio 17 2022&amp;quot;Having generated the projects, now you can build by opening the .sln file in Visual Studio, or build on the command line using:cmake --build . --config ReleaseThe externals will be created in the src/externals folder, move them ~/Documents/Max 9/Packages/nn_terrain/externals/"
                },
                {
                    "url": "/nn_terrain/",
                    "title": "Latent Terrain Synthesis",
                    "content": "Building new musical instruments that compose and interact with AI audio generators.  MaxMSP externals available here, example MaxMSP/Max4Live devices will be available soon.WelcomeLatent terrain is a coordinates-to-latents mapping model for neural audio autoencoders (such as RAVE, Music2Latent). A terrain is a surface map for the autoencoder&#39;s latent space, taking coordinates in a control space as inputs, and producing continuous latent vectors in real-time.Latent terrain aims to open up the creative possibilities of latent space navigation, allowing one to adapt an autoencoder to easier-to-navigate interfaces (such as gestural controllers, stylus and tablets, XY-pads, and more), and build new musical instruments that compose and interact with AI audio generators.An example latent space walk with Music2Latent:Example applicationsSteering a neural audio autoencoder (tutorial coming soon).Building 1D/2D latent granular synthesiser (tutorial coming soon).Latent looping device.Supported autoencodersLatent terrain can work with any audio autoencoder as long as it offers latent variables. However, only a limited number of them have been implemented for MaxMSP, and we have only tested the following models:RAVE Realtime Audio Variational autoEncoder for fast and high-quality neural audio synthesis, by Antoine Caillon and Philippe Esling.Music2Latent-Scripted Music2Latent is a Consistency Autoencoder to encode and decode audio samples, by Marco Pasini, Stefan Lattner, and George Fazekas. We&#39;re using a scripted fork of the original repository.We plan to test the following model in the future:FlowDecvschaos2Get startedDownload and InstallationInstructionsPre-Trained Terrains (Presets)Compiling from SourceGet in touchHi, this is Shuoyang (Jasper). nn.terrain~ is part of my ongoing PhD work on Discovering Musical Affordances in Neural Audio Synthesis, supervised by Anna Xambó Sedó and Nick Bryan-Kinns, and part of the work has been (will be) on putting AI audio generators into the hands of composers/musicians.Therefore, I would love to have you involved in it - if you have any feedback, a features request, a demo / a device / or anything made with nn.terrain, I would love to hear. If you would like to collaborate on anything, please leave a message in this feedback form.AcknowledgementsShuoyang Zheng, the author of this work, is supported by the UKRI Centre for Doctoral Training in Artificial Intelligence and Music [EP/S022694/1]."
                },
                {
                    "url": "/nn_terrain/instructions/overview/",
                    "title": "Overview",
                    "content": "What is neural audio autoencoder and why using latent terrain?  A neural audio autoencoder (such as RAVE) is an AI audio generation tool, it has two components: an encoder and a decoder.The encoder compresses a piece of audio signal into a sequence of latent vectors (a latent trajectory). This compression happens in the time domain, so that the sampling rate goes from 44100Hz (audio sampling rate) to 21.5Hz (latent space sampling rate).The decoder takes the latent trajectory to produce a piece of audio signal. The decoder can also be used as a parametric synthesiser by navigating the latent space (i.e., latent space walk).A latent terrain is a surface map created from the latent trajectory, just like looking at a latent trajectory from above. Audio sample, latent trajectories, and latent terrain. It allows you to navigate latent space of the generative AI like walking on a terrain surface, tailoring the latent space to a low-dimensional (e.g., a 2D plane) control space.And this terrain surface is nonlinear (i.e., able to produce complex sequential patterns), continuous (i.e., allows for smooth interpolations), and tailorable (i.e., DIY your own materials with interactive machine learning).An example latent space walk with Music2Latent:"
                },
                {
                    "url": "/nn_terrain/instructions/load-terrain/",
                    "title": "Using pre-trained terrains",
                    "content": "Feeling like using some already built terrains? They can be loaded like presets.  This video introduces loading a terrain with 2 continuous control channels, navigating an autoencoder with 4 latent dimensions.What we needMake sure to have nn.terrain package and nn~ installed correctly, see Download and Installation for this.Make sure to grab an autoencoder (a .ts file) and a terrain model (a .pt file) from Pre-Trained Terrains (Presets).Synopsis Example can be found in the help file of `nn.terrain`. This tutorial guides you through:A brief introduction of an autoencoder and latent terrain,Loading a pre-trained terrain in MaxMSP,Adding an XY pad to control the navigation in the terrain,Visualising latent vectors (via multisliders),Visualising the terrain (rendering a surface map).Video:"
                },
                {
                    "url": "/nn_terrain/instructions/visualisation/",
                    "title": "Creating visualisations",
                    "content": "Given a terrain with 2D inputs, we can visualise it as a map.  Looking at a terrain from above, we&#39;ll get a greyscale surface map, where brighter pixels denote higher latent value."
                },
                {
                    "url": "/nn_terrain/instructions/build-terrain/",
                    "title": "Building terrains from scratch",
                    "content": "Instructions on building and training a customised terrain using supervised machine learning.  An object nn.terrain~ 2 4 creates an empty terrain with 2 control channels and 4 latent channels.This video introduces building a terrain with 2 continuous control channels, for an autoencoder with 4 latent dimensions.What we needTo build a terrain from scratch, we need a training dataset: pairs of latent trajectories and spatial trajectories.Latent trajectories are sequences of latent vectors encoded from audio buffers.Spatial trajectories are sequences of coordiantes in a control space. For instance:Trajectory of mouse in an XY track padTrajectory of hand gestures in an XYZ 3D spaceTimestamps in a timeline playback systemA terrain is a supervised machine learning model that learns this coordiantes-to-latents pairs, to produce new latent vectors given any coordiantes in the control space, so that the control space can be rendered as a &amp;quot;map&amp;quot; for the latent space. Latent trajectories, spatial trajectories, and latent terrain. Synopsis Example can be found in the help file of `nn.terrain`. This tutorial guides you through:Creating an empty terrain with customised number of inputs, outputs.Gathering latent trajectories from audio buffers, using nn.terrain.encode.Plotting 2D spatial trajectories in nn.terrain.gui with customised length.Training the empty terrain with latent and spatial trajectories.Setting up training datasetMonitoring the training lossVisualising terrain on-the-flySaving checkpointsVideo:"
                },
                {
                    "url": "/nn_terrain/instructions/record-latents/",
                    "title": "Recording latent trajectories",
                    "content": "Feeling like using some already built terrains? They can be used as presets.  Recording training data for a terrain with 3 continuous control channels, for an autoencoder with 64 latent dimensions."
                },
                {
                    "url": "/nn_terrain/instructions/interact/",
                    "title": "Composing and interacting with a terrain",
                    "content": "Programming trajectories in a 2D terrain.  The play mode of nn.terrain.gui offers position-based trajectory playback, which is similar to the play~ object in Max - plays back latent trajectories based on an offset within the trajectory.It can be used with any signal that generates a positional value in milliseconds (e.g., the line~ object).Please see the help file of nn.terrain.gui in Max for details:"
                },
                {
                    "url": "/nn_terrain/posts/hello-post/",
                    "title": "Nothing to tutor at the moment",
                    "content": "The first blog post post open-graph-image Howdy! I am the first blog post of this project. To create content with LibDoc, you can use markdown, inline HTML and widgets.Learn how to adjust blog settings.The image above is also used as Open Graph Image."
                },
                {
                    "url": "/nn_terrain/BuildInstructions/",
                    "title": "./BuildInstructions.md",
                    "content": "  Build InstructionsIf the externals have trouble opening in Max, or doesn&#39;t work correctly with nn_tilde, you might want to build the externals yourself:PrerequisitesMacOS (arm64):Xcode 11 or 12 (you can get from the App Store for free).Download arm64 LibTorch here and unzip it to a known directory. LibTorch&#39;s torch version should be the same as nn_tilde.Install a recent version of CMake (version 3.19 or higher).Windows:Download LibTorch here and unzip it to a known directory. LibTorch&#39;s torch version should be the same as nn_tilde.If you would like to enable GPU training/inference, you&#39;ll need to select the CUDA version of LibTorch, and have the corresponding CUDA ToolKit.Install a recent version of CMake (version 3.19 or higher).Build on MacOSRecursively clone this repository into Max&#39;s Packages folder. Terminal command:git clone https://github.com/jasper-zheng/nn_terrain.git --recursiveIn Terminal, cd into the nn_terrain folder you cloned, and make a new folder named build. and cd into that folder:cd nn_terrainmkdir buildcd buildRun the command below to generate an Xcode project, replace path/to/libtorch to the libtorch folder you&#39;ve downloaded:cmake ../src/ -G Xcode -DCMAKE_PREFIX_PATH=/path/to/libtorch -DCMAKE_BUILD_TYPE=Release -DCMAKE_OSX_ARCHITECTURES=arm64 An Xcode project will be created in this build folder, you can either open the Xcode project and build it from there, or build by running the command below:cmake --build .The .mxo files will be created in the src/externals folder, move them ~/Documents/Max 9/Packages/nn_terrain/externals/Additionally, taken from min-devkit:If you are running on a Mac with Apple Silicon, you might see an error cannot be loaded due to system security policy when loading your externals in Max. To resolve this, you can ad-hoc codesign your external with codesign --force --deep -s - myobject.mxo.Build on WindowsRecursively clone this repository into Max&#39;s Packages folder. Terminal command:git clone https://github.com/jasper-zheng/nn_terrain.git --recurse-submodulesIn Terminal, cd into the nn_terrain folder you cloned, and make a new folder named build. and cd into that folder:cd nn_terrainmkdir buildcd buildThen run the command below to generate a project buildsystem, replace pathtolibtorch to the libtorch folder you&#39;ve downloaded, and make sure Visual Studio 17 2022 is set to your build system generator (run cmake --help to get a list of available options).cmake ..src -A x64 -DCMAKE_PREFIX_PATH=&amp;quot;pathtolibtorch&amp;quot; -G &amp;quot;Visual Studio 17 2022&amp;quot;Having generated the projects, now you can build by opening the .sln file in Visual Studio, or build on the command line using:cmake --build . --config ReleaseThe externals will be created in the src/externals folder, move them ~/Documents/Max 9/Packages/nn_terrain/externals/"
                },
                {
                    "url": "/nn_terrain/posts/",
                    "title": "./core/libdoc_blog.liquid",
                    "content": "  2025-08-18 Jasper Shuoyang Zheng Nothing to tutor at the moment The first blog post 1"
                },
                {
                    "url": "/nn_terrain/tags/",
                    "title": "./core/libdoc_tags.liquid",
                    "content": "  open-graph-image"
                }
]